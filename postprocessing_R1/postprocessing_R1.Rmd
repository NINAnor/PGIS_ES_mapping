---
title: "postprocessing_R1"
author: "R.Spielhofer"
date: "2023-05-30"
output: html_document
---

This markdown will postprocess the whole data after finishing round 1 of the geospatial data. Before starting round 2 it is necessary to run this script.

Basically this script performs the following steps
1 individual and common importance ranking of ES with AHP
1.1 compute the individual AHP matrix
1.2 compute the common AHP matrix

2 Contribution of a single participant to the consensus map for each ES

2.1 compute individuals contribution to ES with leave one out (LOO-MaxEnt)
2.2 compute spatial explicit contribution of individual

# 0. setup
```{r libraries, include=FALSE}
library(leaflet)
library(mapview)
library(sf)
library(dplyr)
library(rgee)
library(stringi)
library(tidyverse)
library(fs)
library(ahpsurvey)
library(bigrquery)
library(DBI)
```


## gee/BQ connection and setup
```{r gee}
siteID_analysis<-"NOR-SNJ"

bq_auth(path = "C:/Users/reto.spielhofer/OneDrive - NINA/Documents/Projects/WENDY/rgee-381312-85272383f82d.json")
con <- dbConnect(
  bigrquery::bigquery(),
  project = "rgee-381312",
  dataset = "data_base",
  billing = "rgee-381312"
)


## get sf_bound according to siteID
site <- tbl(con, "study_site")
adm_code <- select(site, siteID, siteADM2) %>%filter(siteID == siteID_analysis)%>%select(siteADM2)%>% collect()
adm_code<-as.numeric(adm_code)

bound_reg<-ee$FeatureCollection("FAO/GAUL_SIMPLIFIED_500m/2015/level2")$
  filter(ee$Filter$eq("ADM2_CODE",adm_code))


sf_bound <- ee_as_sf(x = bound_reg)

# path of geometries (training polys)-- change to DB solution
geom_path<-"C:/Users/reto.spielhofer/OneDrive - NINA/Documents/Projects/WENDY/PGIS_ES/data_base/poly_R1"

cols   <- c("#e80909", "#fc8803", "#d8e03f", "#c4f25a","#81ab1f")
maxentviz = list(bands= 'probability',min= 0, max= 1, palette= cols)

cols_diff   <- c("#e80909", "#e80909",  "#c4f25a","#c4f25a","#81ab1f")
vis_diff <- list(min = -2, max = 2, palette = cols_diff, values = labels)

ee_Initialize(user = 'r.spielhofer@bluewin.ch')
# 
geometry <- ee$Geometry$Rectangle(
  coords = c(10.30, 63.35, 10.50, 63.5),
  proj = "EPSG:4326",
  geodesic = FALSE
)

## ee layers
lulc <- ee$Image("COPERNICUS/CORINE/V20/100m/2018")
lulc<-lulc$resample("bilinear")$reproject(crs= "EPSG:4326",scale=100)
lulc<-lulc$clip(bound_reg)


acc_pat<-paste0(ee_get_assethome(), '/acc')
acc<-ee$Image(acc_pat)
acc<-acc$resample("bilinear")$reproject(crs= "EPSG:4326",scale=100)

nat_pat<-paste0(ee_get_assethome(), '/natu')
nat<-ee$Image(nat_pat)
nat<-nat$clip(bound_reg)
nat<-nat$resample("bilinear")$reproject(crs= "EPSG:4326",scale=100)
nat<-nat$rename("nat")

# combine unique class count wdw and lulc
comb<-ee$Image$cat(lulc,acc, nat)
bands <- list("landcover","b1","nat")
```

#1 Importance of ES
## Read data
Read pairwise comparisons for a single site from BQ
```{r files / DB}

es_pair <- tbl(con, "es_pair")
es_pair <- select(es_pair, ES_left,ES_right,selection_text,selection_val,userID,siteID,ahp_section) %>%filter(siteID == siteID)%>% collect()

## ahp processing vars
group_vec<-es_pair%>%distinct(ahp_section)
atts4 <- c("cultural","regulating","provisioning")
atts1 <- c("atmo","nat_haz","biodiv")
atts2 <- c("aes","cult","recr")
atts3 <- c("farm","wild","drink_wat","fibres")
atts_list<-list(atts1,atts2,atts3,atts4)
user_vec<-es_pair%>%distinct(userID)

```

## 1.1 individual preferences and consistency
This section computes the individual preferences for all es and each participant. It stores the result in the BQ table "ahp_ind".

```{r}

all_user_list<-list()
for(u in 1:nrow(user_vec)){
  all_groups<-es_pair%>%filter(userID %in% user_vec[u,])
  pref_list<-list() #list to store tmp pref
  cons_list<-list() #list to store tmp consistencies
  for (g in 1:nrow(group_vec)) {
    # subset data
    data<-all_groups%>%filter(ahp_section %in% group_vec[g,])%>%select(userID,selection_val, ES_left, ES_right)
    data$pair<-paste0(data$ES_left,"_",data$ES_right)
    tDat<-data%>%select(selection_val, pair, userID)%>%
      pivot_wider(id_cols = userID, id_expand = F,  names_from = pair, values_from = selection_val)
    tDat<-tDat[, -1]
    
    ## preferences
    atts<-atts_list[[g]]
    
    ahp_ind <- ahp.mat(df = tDat, atts = atts, negconvert = TRUE)
    pref<-ahp.aggpref(ahp_ind, atts, method = "geometric", aggmethod = "eigen", qt = 0)
    a<-as.data.frame(pref)
    pref_list[[g]]<-a
    cons_list[g]<-ahp.cr(ahp_ind, atts, ri = NULL)
    
  }#close group
  main<-as.data.frame(t(pref_list[[4]]))
  reg<-as.data.frame(t(pref_list[[1]]))
  cul<-as.data.frame(t(pref_list[[2]]))
  prov<-as.data.frame(t(pref_list[[3]]))
  
  ## final ranking of es per respondent
  reg<-t(reg*main$regulating)
  cul<-t(cul*main$cultural)
  prov<-t(prov*main$provisioning)
  
  all<-as.data.frame(rbind(reg,prov,cul))
  all<-all%>%rownames_to_column(var = "esID")
  all$userID<-rep(user_vec[u,],nrow(all))
  all$siteID<-rep(siteID,nrow(all))
  all_user_list[[u]]<-all
  
}#close user

es_ranking<-as.data.frame(do.call(rbind, all_user_list))
es_ranking$userID<-as.character(es_ranking$userID)

insert_upload_job("rgee-381312", "data_base", "ahp_ind", es_ranking)

```

## 1.2 common preferences and consistency
This section computes the common preference for each ES and stores the results in the "ahp_all" table.
```{r}

pref_list<-list()
cons_list<-list()
 for(g in 1:nrow(group_vec)){

  data<-es_pair%>%filter(ahp_section %in% group_vec[g,])%>%select(userID,selection_val, ES_left, ES_right)
  data$pair<-paste0(data$ES_left,"_",data$ES_right)
  tDat<-data%>%select(selection_val, pair, userID)%>%
      pivot_wider(id_cols = userID, id_expand = F,  names_from = pair, values_from = selection_val)
  tDat<-tDat[, -1]
    
    ## preferences
  atts<-atts_list[[g]]
    
  ahp_all <- ahp.mat(df = tDat, atts = atts, negconvert = TRUE)
  pref<-ahp.aggpref(ahp_all, atts, method = "geometric", aggmethod = "eigen", qt = 0)
  
  
  a<-as.data.frame(pref)
  pref_list[[g]]<-a
  # cons_list[group_vec[g,]]<-ahp.cr(ahp_all, atts, ri = NULL)
}

main<-as.data.frame(t(pref_list[[4]]))
reg<-as.data.frame(t(pref_list[[1]]))
cul<-as.data.frame(t(pref_list[[2]]))
prov<-as.data.frame(t(pref_list[[3]]))

  ## final ranking of es per respondent
reg<-t(reg*main$regulating)
cul<-t(cul*main$cultural)
prov<-t(prov*main$provisioning)
  
all<-as.data.frame(rbind(reg,prov,cul))
all<-all%>%rownames_to_column(var = "esID")
all$siteID<-rep(siteID,nrow(all))

insert_upload_job("rgee-381312", "data_base", "ahp_all", all)

```


# 2. Individual`s contribution to common ES map
This section recomputes the spatial extrapolation of each ES using Maxent but leaves out each participant once. I then calculates the importance of each participant and the areas the participant contributed most to the consensus map.

## 2.1 leave one out MaxEnt
(read from local files nneds to be changed!!)

1) import all ES polygons per ES --> 10 multipolygon
```{r}
file_list <- as.list(list.files(geom_path, pattern = "*shp", full.names = TRUE))
# Getting all file paths
shapefiles <- geom_path |>
  dir_ls(recurse = TRUE) |>
  str_subset('.shp$')

# Loading all files
sfdf <- shapefiles |>
  map(st_read) |>
  bind_rows()



```

2) compute 10 maps RF with all participants available --> store RMSE & Varimp
```{r}

# overall map per es
eslist<-sfdf%>%filter(siteID == siteID_analysis)%>%select(esID)%>%st_drop_geometry()%>%distinct()


for (i in 1:nrow(eslist)) {
  polygon<-sfdf%>%filter(esID==eslist[i,])
  gee_poly<-rgee::sf_as_ee(polygon, via = "getInfo")
  
   ############ training pts

   ## N background (outside poly points) according to area of extrapolation
          A_roi<-as.numeric(st_area(sf_bound))
          # area of smallest poly
          A_min<-as.numeric(min(st_area(polygon)))
          # area of largest poly
          A_max<-as.numeric(max(st_area(polygon)))       
          
          # max pts for efficient extrapolation each 250x250 cell
          max_pts<- round(A_roi/(300*300),0)
          
          #union of poly in case overlapping
          poly_uni<-st_union(polygon)
          
          # ratio poly area union vs whole area
          poly_area<-as.numeric(sum(st_area(poly_uni)))
          ratio_A<-poly_area/A_roi
          
          ## although zooming on the map while drawing is limited, we assure that at least 10pts are within a poly
          min_in_pts<-10
          abs_min_res<-100
          min_in_eff_pts<-(sqrt(A_min)/abs_min_res)^2
          
          
          if(min_in_eff_pts<min_in_pts){
            pts_min <- min_in_pts
          } else {
            pts_min <- min_in_eff_pts
          }
          
          # amount of background pts
          pts_out<-round(1/ratio_A*pts_min,0)
          
          # sample backgraound pts
          # pts_out = st_sample(sf_bound, pts_out,type="random")
          pts_out = st_sample(sf_bound, max_pts,type="random")
          

          # don`t allow intersection with polygons
          pts_out <- st_difference(st_combine(pts_out), st_combine(test_union)) %>% st_cast('POINT')
          pts_out<-st_as_sf(pts_out)
          pts_out$inside<-rep(0,nrow(pts_out))
          pts_all<-pts_out
          
          # inside pts are area + es value weighted
          for (a in 1:nrow(polygon)) {
            A_tmp <- as.numeric(st_area(polygon[a,]))
            #tmp_ratio<-A_tmp/A_min
            tmp_ratio<-A_tmp/A_roi
            # npts in this poly must be max_pts*tmp_ratio*es_value
            #tmp_pts = st_sample(polygon[i,], round(tmp_ratio*pts_min,0)*polygon[i,]$es_value,type="random")
            tmp_pts = st_sample(polygon[a,], round(max_pts*tmp_ratio,0)*polygon[a,]$es_valu,type="random")
            tmp_pts<-st_as_sf(tmp_pts)
            tmp_pts$inside<-rep(1,nrow(tmp_pts))
            pts_ee<-rbind(pts_all,tmp_pts)
            
          }
          # ee object of sampling pts 6k pts = 7sec
          pts_ee<-rgee::sf_as_ee(pts_ee, via = "getInfo")
          
          # define target bands of comb (indep. var) and sample vars by pts
          pts_ee = comb$select(bands)$sampleRegions(collection= pts_ee,
                                                    properties = list("inside"),
                                                    geometries = T
          )
          
          ############ maxent

          mEntclass = ee$Classifier$amnhMaxent()$train(
            features = pts_ee,
            classProperty = 'inside',
            inputProperties = bands
          )
          
          imageClassified = comb$select(bands)$classify(mEntclass)
          
          ### varImp and ROC takes a lot of time -- postprocessing?
          varImp<- mEntclass$explain()$get("Contributions")$getInfo()%>% #get importance
            as_tibble()%>%#make tibble
            pivot_longer(cols = c(1:ncol(.)))%>% #long df for plotting
            arrange(desc(value))%>% #sort decreasing values
            slice(1:10)
          
          varImp$esID<-rep(eslist[i,],nrow(varImp))
          varImp$siteID<-rep(siteID_analysis,nrow(varImp))
          varImp$userID<-rep("all_user",nrow(varImp))
          varImp<-varImp%>%filter(name !="__unused__")
          colnames(varImp)<-c("var_name","imp_val","esID","siteID","userID")


          AUC_maxent<-mEntclass$explain()$get("Training AUC")$getInfo()%>% #get importance
            as_tibble()
  
          img_assetid <- paste0(ee_get_assethome(), '/R_1/all_part/',eslist[i,],"_", siteID_analysis)
          
          #set features of img
          imageClassified <- imageClassified$set('es_id', eslist[i,],
                                       'siteID', siteID_analysis)
          
          start_time<-Sys.time()
          task_img <- ee_image_to_asset(
            image = imageClassified,
            assetId = img_assetid,
            overwrite = T,
            region = geometry
          )
          
          task_img$start()
print("============= next ES==============")
}



```

### LOO
```{r}
# es_sel<-as.data.frame("recr")

eslist<-sfdf%>%filter(siteID == siteID_analysis)%>%select(esID)%>%st_drop_geometry()%>%distinct()
A_roi<-as.numeric(st_area(sf_bound))

for(m in 1: 1:nrow(eslist)){
  ## for each es_list we need to find the distinct users
  userlist<-sfdf%>%filter(siteID == siteID_analysis, esID == eslist[m,])%>%select(userID)%>%st_drop_geometry()%>%distinct()

  for(n in 1: nrow(userlist)){
    #leave nth user out
    polygon<-sfdf%>%filter(esID==eslist[m,] & userID != userlist[n,] )
  
    gee_poly<-rgee::sf_as_ee(polygon, via = "getInfo")
    
    ## N background (outside poly points) according to area of extrapolation
          
          # area of smallest poly
          A_min<-as.numeric(min(st_area(polygon)))
          # area of largest poly
          A_max<-as.numeric(max(st_area(polygon)))       
          
          # max pts for efficient extrapolation each 250x250 cell
          max_pts<- round(A_roi/(300*300),0)
          
          #union of poly in case overlapping
          poly_uni<-st_union(polygon)
          
          # ratio poly area union vs whole area
          poly_area<-as.numeric(sum(st_area(poly_uni)))
          ratio_A<-poly_area/A_roi
          
          ## although zooming on the map while drawing is limited, we assure that at least 10pts are within a poly
          min_in_pts<-10
          abs_min_res<-100
          min_in_eff_pts<-(sqrt(A_min)/abs_min_res)^2
          
          
          if(min_in_eff_pts<min_in_pts){
            pts_min <- min_in_pts
          } else {
            pts_min <- min_in_eff_pts
          }
          
          # amount of background pts
          pts_out<-round(1/ratio_A*pts_min,0)
          
          # sample backgraound pts
          # pts_out = st_sample(sf_bound, pts_out,type="random")
          pts_out = st_sample(sf_bound, max_pts,type="random")
          

          # don`t allow intersection with polygons
          pts_out <- st_difference(st_combine(pts_out), st_combine(test_union)) %>% st_cast('POINT')
          pts_out<-st_as_sf(pts_out)
          pts_out$inside<-rep(0,nrow(pts_out))
          pts_all<-pts_out
          
          # inside pts are area + es value weighted
          for (a in 1:nrow(polygon)) {
            A_tmp <- as.numeric(st_area(polygon[a,]))
            #tmp_ratio<-A_tmp/A_min
            tmp_ratio<-A_tmp/A_roi
            # npts in this poly must be max_pts*tmp_ratio*es_value
            #tmp_pts = st_sample(polygon[i,], round(tmp_ratio*pts_min,0)*polygon[i,]$es_value,type="random")
            tmp_pts = st_sample(polygon[a,], round(max_pts*tmp_ratio,0)*polygon[a,]$es_valu,type="random")
            tmp_pts<-st_as_sf(tmp_pts)
            tmp_pts$inside<-rep(1,nrow(tmp_pts))
            pts_ee<-rbind(pts_all,tmp_pts)
            
          }
          # ee object of sampling pts 6k pts = 7sec
          pts_ee<-rgee::sf_as_ee(pts_ee, via = "getInfo")
          
          # define target bands of comb (indep. var) and sample vars by pts
          pts_ee = comb$select(bands)$sampleRegions(collection= pts_ee,
                                                    properties = list("inside"),
                                                    geometries = T
          )
          
          ############ maxent

          mEntclass = ee$Classifier$amnhMaxent()$train(
            features = pts_ee,
            classProperty = 'inside',
            inputProperties = bands
          )
          
          imageClassified = comb$select(bands)$classify(mEntclass)
          
          ### varImp and ROC takes a lot of time -- postprocessing?
          varImp<- mEntclass$explain()$get("Contributions")$getInfo()%>% #get importance
            as_tibble()%>%#make tibble
            pivot_longer(cols = c(1:ncol(.)))%>% #long df for plotting
            arrange(desc(value))%>% #sort decreasing values
            slice(1:10)
          
          varImp$esID<-rep(eslist[m,],nrow(varImp))
          varImp$siteID<-rep(siteID_analysis,nrow(varImp))
          varImp$userID<-rep(userlist[n,],nrow(varImp))
          varImp$spatial_delphi_round<-rep(1,nrow(varImp))
          varImp<-varImp%>%filter(name !="__unused__")
          colnames(varImp)<-c("var_name","imp_val","esID","siteID","userID","spatial_delphi_round")
          ## store on bq
          insert_upload_job("rgee-381312", "data_base", "var_imp", varImp)


          AUC_maxent<-mEntclass$explain()$get("Training AUC")$getInfo()%>% #get importance
            as_tibble()
  
          img_assetid <- paste0(ee_get_assethome(), '/R_1/leave_one_out/',userlist[n,],"_",eslist[m,],"_", siteID_analysis)
          
          #set features of img
          imageClassified <- imageClassified$set('esID', eslist[m,],
                                       'siteID', siteID_analysis,
                                       'leftout_userID',userlist[n,])
          
          start_time<-Sys.time()
          task_img <- ee_image_to_asset(
            image = imageClassified,
            assetId = img_assetid,
            overwrite = T,
            region = geometry
          )
          
          task_img$start()
          
          print("============= next user==============")

  }#close user
  print("============= next ES==============")
}#close es
```



## 2.2 areas of high contribution
1) ES all - ES all without participant XY?

```{r}
# es_selected<-"recr"
# 
# leftout<-ee$ImageCollection(paste0(ee_get_assethome(), '/R_1/leave_one_out'))$filter(ee$Filter$eq('left_out_userID', "KUUFYZ5gYt"))$filter(ee$Filter$eq('esID',"recr"))$filter(ee$Filter$eq('siteID',"NOR-SNJ"))$toBands()
# 
# all<-ee$Image(paste0(ee_get_assethome(), '/R_1/all_part'))$filter(ee$Filter$eq('left_out_userID'))
# 
# diff<-all$subtract(leftout)
# 
# Map$addLayer(
#         eeObject = diff,
#         vis_diff,
#         opacity = .7
#       )

```

